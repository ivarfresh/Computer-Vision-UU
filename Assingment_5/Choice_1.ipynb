{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63f28c5-3fab-46ab-a425-1f0b1585b128",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2349-93ab-4576-8cb9-3cb85f73269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34d917-139a-4479-b993-9dbb5c7cb1a7",
   "metadata": {},
   "source": [
    "## Data Preprocess & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5b3f7d6-0174-4023-9b98-b9511eb23d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_hmdb51 = [\"clap\", \"climb\", \"drink\", \"jump\", \"pour\", \"ride_bike\", \"ride_horse\", \n",
    "        \"run\", \"shoot_bow\", \"smoke\", \"throw\", \"wave\"]\n",
    "\n",
    "TRAIN_TAG, TEST_TAG = 1, 2\n",
    "train_files, test_files = [], []\n",
    "train_labels, test_labels = [], []\n",
    "split_pattern_name = f\"*test_split1.txt\"\n",
    "split_pattern_path = os.path.join('new_HMDB51/test_train_splits', split_pattern_name)\n",
    "annotation_paths = glob.glob(split_pattern_path)\n",
    "for filepath in annotation_paths:\n",
    "    class_name = '_'.join(filepath.split('/')[-1].split('_')[:-2])\n",
    "    if class_name not in keep_hmdb51:\n",
    "        continue  # skipping the classes that we won't use.\n",
    "    with open(filepath) as fid:\n",
    "        lines = fid.readlines()\n",
    "    for line in lines:\n",
    "        video_filename, tag_string = line.split()\n",
    "        tag = int(tag_string)\n",
    "        if tag == TRAIN_TAG:\n",
    "            train_files.append(video_filename)\n",
    "            train_labels.append(class_name)\n",
    "        elif tag == TEST_TAG:\n",
    "            test_files.append(video_filename)\n",
    "            test_labels.append(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d9fbf-ff0d-495e-8b17-487923042ade",
   "metadata": {},
   "source": [
    "## Frame Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ab055-ffac-40a0-9bf8-754db7a126f3",
   "metadata": {},
   "source": [
    "### Start, End & Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4aa7f65-57c1-4de5-8795-36c2e314bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['start', 'end', 'random']\n",
    "\n",
    "for option in options:\n",
    "    # Loop over all categories/classes and extract random frame\n",
    "    for category in keep_hmdb51:\n",
    "        # set the path to the directory containing the videos\n",
    "        video_dir = f'new_HMDB51/video_data/{category}'\n",
    "\n",
    "        # get a list of all .avi files in the directory\n",
    "        video_files = [f for f in os.listdir(video_dir) if f.endswith('.avi')]\n",
    "\n",
    "        # iterate over each video file\n",
    "        for video_file in video_files:\n",
    "\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            video = cv2.VideoCapture(video_path)\n",
    "            num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "            if option == 'start':\n",
    "                # generate a frame near the start \n",
    "                frame_num = num_frames//10\n",
    "            elif option == 'end':\n",
    "                # generate a frame near the end\n",
    "                frame_num = num_frames//1.1\n",
    "            elif option == 'random':\n",
    "                # generate a random frame \n",
    "                frame_num = random.randint(5, num_frames - 5)\n",
    "\n",
    "            # set the frame number to read\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "            ret, frame = video.read()\n",
    "            video.release()\n",
    "            if ret:\n",
    "                path = f'new_HMDB51/frames/{option}/{category}'\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "                # set the path to save the image\n",
    "                img_path = os.path.join(path, os.path.splitext(video_file)[0] + '.jpg')\n",
    "\n",
    "                # save the image\n",
    "                cv2.imwrite(img_path, frame)\n",
    "\n",
    "            else:\n",
    "                print('Unable to extract frame!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f205b3a-c680-4331-9a14-4cd446eb76c0",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c880e-b2a5-4954-a363-ed31137bf2a6",
   "metadata": {},
   "source": [
    "### Start frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeaa8a6-3df4-42cb-a6d3-f0eb2b448e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "for file in train_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/start'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_train.append(img)\n",
    "                \n",
    "for file in test_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/start'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_test.append(img)\n",
    "                \n",
    "x_train = np.asarray(x_train)/255.\n",
    "x_test = np.asarray(x_test)/255.\n",
    "\n",
    "# Dict to convert string labels to ints\n",
    "str_to_int = {\"clap\":0, \"climb\":1, \"drink\":2, \"jump\":3, \"pour\":4, \"ride_bike\":5, \"ride_horse\":6, \n",
    "              \"run\":7, \"shoot_bow\":8, \"smoke\":9, \"throw\":10, \"wave\":11}\n",
    "\n",
    "y_train = np.array([str_to_int[label] for label in train_labels])\n",
    "y_test = np.array([str_to_int[label] for label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca90bb-7129-4fc0-b4d1-94ccb212c1e3",
   "metadata": {},
   "source": [
    "### End frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe32660-6faa-4b91-a7a0-4eef9b22a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "for file in train_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/end'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_train.append(img)\n",
    "                \n",
    "for file in test_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/end'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_test.append(img)\n",
    "                \n",
    "x_train = np.asarray(x_train)/255.\n",
    "x_test = np.asarray(x_test)/255.\n",
    "\n",
    "# Dict to convert string labels to ints\n",
    "str_to_int = {\"clap\":0, \"climb\":1, \"drink\":2, \"jump\":3, \"pour\":4, \"ride_bike\":5, \"ride_horse\":6, \n",
    "              \"run\":7, \"shoot_bow\":8, \"smoke\":9, \"throw\":10, \"wave\":11}\n",
    "\n",
    "y_train = np.array([str_to_int[label] for label in train_labels])\n",
    "y_test = np.array([str_to_int[label] for label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776cdd3-e896-4005-ac70-0789789e8967",
   "metadata": {},
   "source": [
    "### Random frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739e4ca-bf62-452a-b29e-8be5ece62c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "\n",
    "for file in train_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/random'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_train.append(img)\n",
    "                \n",
    "for file in test_files:\n",
    "    vid_name = file[:-4]\n",
    "    for path, _, files in os.walk('new_HMDB51/frames/random'):\n",
    "        for file_name in files:\n",
    "            if file_name[:-4] == vid_name:\n",
    "                img = cv2.imread(os.path.join(path, file_name))\n",
    "                img = cv2.resize(img, (112, 112))\n",
    "                x_test.append(img)\n",
    "                \n",
    "x_train = np.asarray(x_train)/255.\n",
    "x_test = np.asarray(x_test)/255.\n",
    "\n",
    "# Dict to convert string labels to ints\n",
    "str_to_int = {\"clap\":0, \"climb\":1, \"drink\":2, \"jump\":3, \"pour\":4, \"ride_bike\":5, \"ride_horse\":6, \n",
    "              \"run\":7, \"shoot_bow\":8, \"smoke\":9, \"throw\":10, \"wave\":11}\n",
    "\n",
    "y_train = np.array([str_to_int[label] for label in train_labels])\n",
    "y_test = np.array([str_to_int[label] for label in test_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94a4be-aee6-49e7-9416-7547c2553992",
   "metadata": {},
   "source": [
    "## Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70460d0f-873a-44a2-9ab4-0d2d2349cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline from Assignment 4\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(112, 112, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=12, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load weights from Stanford dataset\n",
    "model.load_weights('weights/stanford.h5')\n",
    "\n",
    "# Freeze the convolutional layers of the model\n",
    "model.layers[0].trainable = False\n",
    "model.layers[2].trainable = False\n",
    "model.layers[4].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613990a8-eeb2-4594-ae6a-c4ea2c17ee49",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995fa87-5316-454d-a5de-3e0c89c0f2cd",
   "metadata": {},
   "source": [
    "### Start frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14c5ef8-b8d7-4fcd-af24-996d1bd8b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 20:32:27.177206: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 126443520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 13s 439ms/step - loss: 3.3480 - accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 11s 387ms/step - loss: 2.0558 - accuracy: 0.3429\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 10s 368ms/step - loss: 1.7021 - accuracy: 0.4512\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 10s 386ms/step - loss: 1.3533 - accuracy: 0.5762\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 11s 397ms/step - loss: 1.0211 - accuracy: 0.6810\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 11s 392ms/step - loss: 0.7043 - accuracy: 0.7940\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 11s 403ms/step - loss: 0.5090 - accuracy: 0.8536\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 10s 384ms/step - loss: 0.3510 - accuracy: 0.9083\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 11s 405ms/step - loss: 0.2563 - accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 10s 383ms/step - loss: 0.1667 - accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e394a8-241b-475d-8461-d1047effe90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 74ms/step - loss: 3.3262 - accuracy: 0.2611\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f7cf7-6dfb-4b66-8809-fa0b89ac395d",
   "metadata": {},
   "source": [
    "### End frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e901d6ae-eb92-4848-880f-9c95caf42522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 16s 535ms/step - loss: 3.2762 - accuracy: 0.1940\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 11s 424ms/step - loss: 2.0216 - accuracy: 0.3405\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 10s 386ms/step - loss: 1.6396 - accuracy: 0.4667\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 11s 399ms/step - loss: 1.2948 - accuracy: 0.5821\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 11s 412ms/step - loss: 0.9673 - accuracy: 0.7012\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 10s 388ms/step - loss: 0.7364 - accuracy: 0.7810\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 10s 385ms/step - loss: 0.5239 - accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 11s 410ms/step - loss: 0.3143 - accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 11s 398ms/step - loss: 0.2113 - accuracy: 0.9560\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 11s 389ms/step - loss: 0.1697 - accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9f1318-f9a3-4d3b-bc14-34c6e84f4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 70ms/step - loss: 3.1617 - accuracy: 0.2806\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b02a18-5076-4ccd-9b2b-0c45d19ab00e",
   "metadata": {},
   "source": [
    "### Random frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be8a75f-8525-4078-a114-2bed211c19a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 20:46:38.050349: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 126443520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 12s 413ms/step - loss: 3.2861 - accuracy: 0.2202\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 10s 382ms/step - loss: 2.0655 - accuracy: 0.3214\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 10s 378ms/step - loss: 1.7042 - accuracy: 0.4417\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 10s 380ms/step - loss: 1.3842 - accuracy: 0.5750\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 11s 423ms/step - loss: 1.0231 - accuracy: 0.6845\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 11s 420ms/step - loss: 0.7356 - accuracy: 0.7833\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 10s 385ms/step - loss: 0.5111 - accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 10s 374ms/step - loss: 0.3470 - accuracy: 0.9024\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 10s 375ms/step - loss: 0.2094 - accuracy: 0.9452\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 10s 376ms/step - loss: 0.1489 - accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cdb49c3-96c0-4da0-935e-4b349edc58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 69ms/step - loss: 3.1377 - accuracy: 0.2944\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ba7ac-7b45-4b93-8272-7c7ed0837c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
